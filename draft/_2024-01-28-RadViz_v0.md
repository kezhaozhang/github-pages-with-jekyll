---
title: "Radviz projection and feature importance in regression"
date: 2024-01-28
typora-root-url: ./..
---

Radviz is a visualization method that projects multidimensional data onto a 2D plane. The plot can show the balance between the dimensions of the data. In this note, we first show how the projection is computed. Then, we apply the Radviz plot to one multivariate regression and demonstrate to the data that it can identify the important features in the regression. 



### Radviz Projection

Suppose an $M$-dimensional data point,   $\bf{x} = [x_1, x_2, \ldots, x_M]$, is to be mapped on a 2D plane and represented by a 2D vector $\mathbf{v}$. The Radviz projection uses a method analogous to finding the position of a mass connected to $M$ anchor points, $A_1$, $A_2$, $\ldots$, $A_M$,  on a circle by strings. These anchor points represent the dimensions of the data and are uniformly distributed on the circle. The component value $x_i$ represents the strength of the $i$-th string, which connects the mass and the $i$-th anchor point $A_i$. The mass settles at the location $\mathbf{v}$ when forces of all the springs are balanced. An example of 4D data is shown in Figure 1.

<figure>
  <center>
  <img src="/assets/images/radviz_spring_model.svg" width="700">
   </center>
  <center>
    <figcaption> Figure 1. An illustration of the Radviz project for a 4-dimensional data point <b><i>x</i></b>=[<i>x</i><sub>1</sub>,<i>x</i><sub>2</sub>, <i>x</i><sub>3</sub>, <i>x</i><sub>4</sub>]. <b><i>A</i></b><sub>i</sub> are the anchor points on the circle. Vector <b><i>v</i></b> represents the location of the projected data. The value <i>x</i><sub>i</sub> (<i>i</i>=1,2,3,4) represents the strength of anchor point <i>A</i><sub>i</sub>'s influence.
    </figcaption>
  </center>
</figure>

Let vectors $\mathbf{A}_i$ denote the locations of the anchor points on the circle. The total forces on the mass, located at $\mathbf{v}$, is  zero:


$$
\sum_{i=1}^{M} (\mathbf{A}_i -\mathbf{v}) x_i = 0 \notag
$$



Therefore, the location of the mass is


$$
\mathbf{v} = \frac{\sum_{i=1}^M \mathbf{A}_i x_i}{\sum_{i=1}^M x_i}.\label{eqn:radviz}
$$



The location of the projection on the 2D plane is the weighted average of the anchor points' locations. 

The variables $x_i$ are scaled to the range of $[0, 1]$ before the calculation with Equation ($\ref{eqn:radviz}$​) so that the mapped points will stay in a confined region.



### An Example 

We apply Radviz to a dataset which has six columns, $x_1$, $x_2$, $x_3$, $x_4$, $x_5$, and $y$​.  The scatter matrix plot of these variables is shown in Figure 2.




<figure>
  <center>
  <img src="/assets/images/radviz_x_y_scatter_matrix.svg" width="800">
   </center>
  <center>
    <figcaption> Figure 2. Scatter matrix plots of variables.
    </figcaption>
  </center>
</figure>


#### Radviz and Parallel Coordinates Plots

Before we build a regression model of $y$ on $x_i$, we apply Equation ($\ref{eqn:radviz}$) to $[ x_1, x_2, x_3, x_4, x_5]$ to generate the mapping on the 2D plane.


The resultant Radviz plot is shown in Figure 3. The color of the data points represents the value of $y$. It can be seen that the gradient of the $y$ value is more or less parallel to the line going through the anchor point $x_3$ and the circle's center, indicating that $x_3$ has a strong effect on $y$. On the opposite end of this direction lie the anchor points $x_1$ and $x_5$, indicating that both of them are also important. The anchor points $x_2$ and $x_4$ are located orthogonal to the direction of the gradient of $y$, they are the least important features.

<figure>
  <center>
  <img src="/assets/images/radviz_ggplot_abline.svg" width="600">
   </center>
  <center>
    <figcaption> Figure 3. Radviz plot of the data. The color represents the value of <i>y</i>. The red dashed line goes through the anchor point corresponding to <i>x</i><sub>3</sub> and the circle's center.
    </figcaption>
  </center>
</figure>



As a reference, the data is plotted with the parallel coordinates plot, which also uses anchor points. As shown in Figure 4,  The parallel coordinates plot shows some clear trends, for example, larger $y$ value tends to have higher $x_1$, lower $x_2$ and $x_3$; but there is no clear trend for $x_5$. However, unlike the Radviz plot,  the parallel coordinates plot does not reveal the relative importance of the variables $x_i$. 



<figure>
  <center>
  <img src="/assets/images/radviz_parallel_coordinates.svg" width="600">
   </center>
  <center>
    <figcaption> Figure 4. Parallel coordinates plot of the data. 
    </figcaption>
  </center>
</figure>



#### Feature Importance in Regression Model

Linear regression models of $y$ on $x_i$ are built to evaluate feature importance. For a given number of predictors, all possible combinations of variables selected from $x_i$, $i=1,2,3,4,5$ are used as predictors in the model, the model performances are compared.

With one predictor, the table below shows that $x_3$ has the best performance, i.e., the lowest mse (mean squared error), AIC, and BIC, and the highest $R^2$. $x_1$ is a close second.



| Predictor | mse  | AIC  | BIC  | $R^2$  |
| :-------: | :--: | :--: | :--: | :----: |
|   $x_3$   | 0.69 | 3607 | 3617 |  0.31  |
|   $x_1$   | 0.73 | 3689 | 3700 |  0.27  |
|   $x_2$   | 0.91 | 4001 | 4011 | 0.095  |
|   $x_4$   | 0.91 | 4002 | 4012 | 0.094  |
|   $x_5$   | 0.99 | 4140 | 4151 | 0.0039 |



When there are two predictors in the model, $(x_1, x_5)$ and $(x_1, x_3)$ are the top two combinations, as shown in the table below.

|  Predictors   | mse  | AIC  | BIC  | $R^2$ |
| :-----------: | :--: | :--: | :--: | :---: |
| $x_1$,  $x_5$ | 0.63 | 3462 | 3478 | 0.37  |
| $x_1$, $x_3$  | 0.65 | 3509 | 3525 | 0.35  |
| $x_3$, $x_4$  | 0.65 | 3523 | 3539 | 0.35  |
| $x_3$, $x_5$  | 0.68 | 3573 | 3589 | 0.33  |
| $x_2$, $x_3$  | 0.68 | 3583 | 3599 | 0.32  |
| $x_1$, $x_2$  | 0.69 | 3599 | 3615 | 0.31  |
| $x_1$, $x_4$  | 0.70 | 3634 | 3650 | 0.30  |
| $x_2$, $x_4$  | 0.72 | 3670 | 3686 | 0.28  |
| $x_4$, $x_5$  | 0.90 | 3998 | 4014 | 0.097 |
| $x_2$, $x_5$  | 0.91 | 4003 | 4019 | 0.094 |

With three predictors,  $x_1$, $x_3$, and $x_5$ is the best combination.

The regression model result is consistent with the Radviz finding.



### References

Hoffman, P., Grinstein, G., and Pinkney, D. [*Dimensional anchors: a graphic primitive for multidimensional multivariate information visualizations.*](https://dl.acm.org/doi/10.1145/331770.331775) Proceedings of the NPIVM 99, 1999

Brunsdon, C., Fotheringham, A., and Charlton, M, [*The RADVIZ Approach to Visualisation*](http://www.agocg.ac.uk/reports/visual/casestud/brunsdon/radviz.htm) in [*An Investigation of Methods for Visualising Highly Multivariate Datasets*](http://www.agocg.ac.uk/reports/visual/casestud/brunsdon/abstract.htm)
